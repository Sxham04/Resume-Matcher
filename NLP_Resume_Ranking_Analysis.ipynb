{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c6886-9b45-4f4e-997d-004bd539398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install pymupdf spacy pandas\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2687a062-14e8-40e1-89b6-469990d261ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "print(\"Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d0a673-4a95-48ca-93e5-4894171b966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "raw_text = extract_text_from_pdf(\"data/resume/Demo Resume.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42333d12-59a9-41d0-9cc8-435d41a25c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n \\n \\n \\n \\n \\n PROFESSIONAL SUMMARY                                                                                                                                             .              \\nBTech CSE student with strong programming skills and a keen interest in machine learning. Quick learner with problem-solving \\nabilities and enthusiasm for applying ML to real-world solutions. \\n EDUCATION                                                                                                                                                                        . \\nBachelor’s of Technology | Computer Science 2023-2027    DIT University, Dehradun, Uttarakhand \\nCGPA: 8.55 \\nClass 12th (CBSE) |2022-2023 \\n80.5 %| St. Luke’s Sr. Sec. School, Solan, Himachal Pradesh  \\nClass 10th  (CBSE) | 2020-2021 \\n75.6% |  St. Luke’s Sr. Sec. School, Solan, Himachal Pradesh \\n SKILLS                                                                                                                                                                                                                       . \\nTechnical -Python, Java, C, Machine Learning beginner, DSA \\nInterpersonal - Adaptability, Communication, Team Management, Critical Thinking, Problem Solving Abilities. \\n \\n PROJECTS                                                                                                                                                                            . \\nCustomer Churn prediction using Machine Learning \\n• \\nDeveloped a machine learning model to predict customer churn, achieving high accuracy by comparing and selecting the \\nbest-performing model from Decision Trees, Random Forest, and XGBoost. \\n• \\nUtilized Python and key libraries (Scikit-learn, Pandas) to perform extensive data preprocessing, feature engineering, and \\nhyperparameter tuning across three classification models. \\n• \\nAnalyzed model performance and feature importance to identify key drivers of customer churn, providing actionable \\ninsights that can be used to inform targeted retention strategies. \\nSimple inventory management system in java \\n• \\nDeveloped an inventory management system using Java, featuring real-time tracking of product stock, sales, and supplier \\ninformation. \\n• \\nImplemented robust database connectivity with JDBC to manage CRUD operations for product data, ensuring data \\npersistence and integrity. \\n• \\nEngineered core functionalities including product search, stock alerts for low inventory, and transaction logging to \\nstreamline business operations. \\nGraph Visualization with Dijkstra's Algorithm in Java \\n• \\nDeveloped a Java GUI-based application to visually represent and interact with a graph data structure. \\n• \\nImplemented Dijkstra's algorithm to compute the shortest path between nodes. \\n• \\nThe application dynamically visualizes the algorithm's execution, highlighting the shortest path in real-time. \\n \\n \\n \\nSoham Sharma \\nBTech CSE(AI&ML) \\n8580612408 \\nsharma.soham04@gmail.com \\nLinkedIn Id: linkedin.com/in/soham-sharma-\\n662738385/  \\n CERTIFICATIONS                                                                                                                                                                .  \\nOCI AI Foundations Course - Oracle \\n• \\nProficient in core AI/ML fundamentals (NLP, Computer Vision, modeling) with hands-on experience applying Oracle Cloud \\nInfrastructure (OCI) AI services for language, vision, speech, and generative AI solutions. \\n \\nJava Intermediate Course - Coursera \\n• \\nMastery of Object-Oriented Programming (OOP) principles, including inheritance and polymorphism, applied to develop \\nmodular and reusable Java applications. Proficient in intermediate Java concepts (collections, file I/O, exception handling) \\nfor practical software development. \\n \\nPython intermediate course - Udemy \\n• \\nProficient in core and intermediate Python programming (OOP, functions, error handling, file operations) Strong \\nfoundation in advanced Python concepts, including regular expressions and external libraries, for solving real-world \\nproblems. Prepared for data science, web development, and automation roles. \\n \\n EXTRA CURRICULAR ACHIEVEMENTS                                                                                                                                . \\n \\n• \\nCurrent Research Club coordinator DIT University \\n• \\nParticipated in school and college art & craft competition. \\n• \\nHosted and managed various fests at school as well as in college. \\n• \\nParticipated in closing ceremony of the intramural program. \\n INTERESTS & HOBBIES                                                                                                                                                       . \\n• \\nArt & Craft \\n• \\nWatching movies/shows \\n• \\nListen to Music  \\n \\n PERSONAL DETAILS                                                                                                                                                           .  \\nGender: Male                                                                                              Date of Birth: 09/09/2004 \\nMarital Status:                                                                                            Known Languages: Hindi, English,  \\nCurrent Address: Dehradun                                                                      Phone Numbers: 8580612408 \\nEmails: sharma.soham04@gmail.com \\n \\n \\n \\n \\n \\n    \\n \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5abd75a-73a2-4954-b065-341a24e29dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter detected...\n",
      "3 channel Terms of Service accepted\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\sharm\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - spacy-model-en_core_web_sm\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2025.11.12 |       h4c7d964_0         149 KB  conda-forge\n",
      "    openssl-3.1.0              |       hcfcfb64_3         7.1 MB  conda-forge\n",
      "    spacy-model-en_core_web_sm-3.1.0|     pyhd8ed1ab_0        13.4 MB  conda-forge\n",
      "    ucrt-10.0.26100.0          |       h57928b3_0         678 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        21.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  spacy-model-en_co~ conda-forge/noarch::spacy-model-en_core_web_sm-3.1.0-pyhd8ed1ab_0 \n",
      "  ucrt               conda-forge/win-64::ucrt-10.0.26100.0-h57928b3_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    anaconda/win-64::ca-certificates-2025~ --> conda-forge/noarch::ca-certificates-2025.11.12-h4c7d964_0 \n",
      "  openssl              pkgs/main::openssl-3.0.16-h3f729d1_0 --> conda-forge::openssl-3.1.0-hcfcfb64_3 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "spacy-model-en_core_ | 13.4 MB   |            |   0% \n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.26100.0    | 678 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 149 KB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 149 KB    | #          |  11% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.26100.0    | 678 KB    | 2          |   2% \u001b[A\u001b[A\n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 149 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 149 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.26100.0    | 678 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    | 8          |   8% \u001b[A\n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    | ##8        |  29% \u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.26100.0    | 678 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ucrt-10.0.26100.0    | 678 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "spacy-model-en_core_ | 13.4 MB   |            |   0% \n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    | ####6      |  47% \u001b[A\n",
      "spacy-model-en_core_ | 13.4 MB   |            |   1% \n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    | ######4    |  64% \u001b[A\n",
      "spacy-model-en_core_ | 13.4 MB   | 2          |   3% \n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    | #######9   |  80% \u001b[A\n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    | #########5 |  95% \u001b[A\n",
      "spacy-model-en_core_ | 13.4 MB   | 5          |   5% \n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    | ########## | 100% \u001b[A\n",
      "spacy-model-en_core_ | 13.4 MB   | #5         |  16% \n",
      "spacy-model-en_core_ | 13.4 MB   | ##5        |  26% \n",
      "spacy-model-en_core_ | 13.4 MB   | ###5       |  35% \n",
      "\n",
      "openssl-3.1.0        | 7.1 MB    | ########## | 100% \u001b[A\n",
      "spacy-model-en_core_ | 13.4 MB   | ####5      |  46% \n",
      "spacy-model-en_core_ | 13.4 MB   | #####5     |  56% \n",
      "spacy-model-en_core_ | 13.4 MB   | ######6    |  66% \n",
      "spacy-model-en_core_ | 13.4 MB   | #######6   |  76% \n",
      "spacy-model-en_core_ | 13.4 MB   | ########6  |  86% \n",
      "spacy-model-en_core_ | 13.4 MB   | #########6 |  97% \n",
      "spacy-model-en_core_ | 13.4 MB   | ########## | 100% \n",
      "spacy-model-en_core_ | 13.4 MB   | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharm\\anaconda3\\Lib\\site-packages\\spacy\\util.py:969: UserWarning: [W095] Model 'en_core_web_sm' (3.1.0) was trained with spaCy v3.1.0 and may not be 100% compatible with the current version (3.8.11). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded in Conda base!\n"
     ]
    }
   ],
   "source": [
    "# Install using conda's internal installer\n",
    "!conda install -c conda-forge spacy-model-en_core_web_sm -y\n",
    "\n",
    "# Restart the spacy registry in this session\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Model successfully loaded in Conda base!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c530eef0-438a-4846-9879-3ad0f9bda5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned output: software engineer year experience python\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm  # Changed from md to sm\n",
    "import re\n",
    "\n",
    "# Load the small model that we successfully installed\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Basic cleaning using Regex\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text) \n",
    "    \n",
    "    # 2. NLP processing\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 3. Tokenization, Lemmatization, and Stopword removal\n",
    "    cleaned_tokens = [\n",
    "        token.lemma_ for token in doc \n",
    "        if not token.is_stop and not token.is_punct and not token.is_space\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "# Test the cleaner\n",
    "test_text = \"I am a Software Engineer with 5 years of experience in Python.\"\n",
    "print(f\"Cleaned output: {clean_text(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51219cd4-4b34-4dc2-8907-652e88dbbe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 5 resumes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Demo Resume.pdf</td>\n",
       "      <td>professional summary btech cse student strong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demo Resume2.pdf</td>\n",
       "      <td>professional summary btech cse student strong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>res.pdf</td>\n",
       "      <td>soham sharma sharmasohamgmailcom linkedin gith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res2.pdf</td>\n",
       "      <td>soham sharma sharmasohamgmailcom linkedin gith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>res3.pdf</td>\n",
       "      <td>soham sharma sharmasohamgmailcom linkedin gith...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Filename                                       Cleaned_Text\n",
       "0   Demo Resume.pdf  professional summary btech cse student strong ...\n",
       "1  Demo Resume2.pdf  professional summary btech cse student strong ...\n",
       "2           res.pdf  soham sharma sharmasohamgmailcom linkedin gith...\n",
       "3          res2.pdf  soham sharma sharmasohamgmailcom linkedin gith...\n",
       "4          res3.pdf  soham sharma sharmasohamgmailcom linkedin gith..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "resume_folder = \"data/resume\" \n",
    "\n",
    "resume_data = []\n",
    "\n",
    "# check if folder exists, then loop through files\n",
    "if os.path.exists(resume_folder):\n",
    "    for filename in os.listdir(resume_folder):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(resume_folder, filename)\n",
    "            \n",
    "            raw_text = extract_text_from_pdf(file_path)\n",
    "\n",
    "            cleaned_text = clean_text(raw_text)\n",
    "            \n",
    "            # Save results\n",
    "            resume_data.append({\n",
    "                \"Filename\": filename,\n",
    "                \"Cleaned_Text\": cleaned_text\n",
    "            })\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(resume_data)\n",
    "    print(f\"Successfully processed {len(df)} resumes.\")\n",
    "    display(df.head()) \n",
    "else:\n",
    "    print(f\"Error: The folder '{resume_folder}' does not exist. Please create it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a13997a-2be8-4d9a-a4e8-9e01443ce43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Job Description:\n",
      "look software engineer proficient python datum science ideal candidate experience nlp machine learn building web application streamlit flask\n"
     ]
    }
   ],
   "source": [
    "job_description = \"\"\"\n",
    "We are looking for a Software Engineer proficient in Python and Data Science. \n",
    "The ideal candidate should have experience with NLP, machine learning, \n",
    "and building web applications using Streamlit or Flask.\n",
    "\"\"\"\n",
    "\n",
    "cleaned_job_desc = clean_text(job_description)\n",
    "print(\"Cleaned Job Description:\")\n",
    "print(cleaned_job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24722e2e-f21c-4452-b369-9d739d798b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 Complete! Data saved to processed_resumes.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"processed_resumes.csv\", index=False)\n",
    "print(\"Phase 1 Complete! Data saved to processed_resumes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ebb6b-f269-4ccd-af13-6d7e8e4a1b26",
   "metadata": {},
   "source": [
    "PHASE 2: Ranking the resume's based on similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39423ed2-e46b-4dcb-9225-b88e41e250ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharm\\AppData\\Local\\Temp\\ipykernel_11260\\2638746826.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  return resume_doc.similarity(job_doc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ranked Candidates ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Match_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Demo Resume.pdf</td>\n",
       "      <td>0.940091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demo Resume2.pdf</td>\n",
       "      <td>0.940091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>res.pdf</td>\n",
       "      <td>0.921607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res2.pdf</td>\n",
       "      <td>0.921607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>res3.pdf</td>\n",
       "      <td>0.921607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Filename  Match_Score\n",
       "0   Demo Resume.pdf     0.940091\n",
       "1  Demo Resume2.pdf     0.940091\n",
       "2           res.pdf     0.921607\n",
       "3          res2.pdf     0.921607\n",
       "4          res3.pdf     0.921607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_similarity(resume_text, job_desc_text):\n",
    "    resume_doc = nlp(resume_text)\n",
    "    job_doc = nlp(job_desc_text)\n",
    "    \n",
    "    # spacy's built-in similarity uses cosine similarity\n",
    "    return resume_doc.similarity(job_doc)\n",
    "\n",
    "# apply the function to our DataFrame\n",
    "df['Match_Score'] = df['Cleaned_Text'].apply(lambda x: calculate_similarity(x, cleaned_job_desc))\n",
    "\n",
    "# sort the results so the best match is at the top\n",
    "df = df.sort_values(by='Match_Score', ascending=False)\n",
    "\n",
    "# Display the ranked candidates\n",
    "print(\"--- Ranked Candidates ---\")\n",
    "display(df[['Filename', 'Match_Score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b5ff4-a0da-4617-84d9-06f816450976",
   "metadata": {},
   "source": [
    "0.85+: Excellent match. The candidate has most of the required keywords and context.\n",
    "\n",
    "0.60 - 0.80: Good match. Likely has the right background but might be missing specific tools.\n",
    "\n",
    "Below 0.50: Poor match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "499b3e00-a915-4d4e-b0e0-d6c66e80e003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Match_Score</th>\n",
       "      <th>Key_Skills_Matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Demo Resume.pdf</td>\n",
       "      <td>0.940091</td>\n",
       "      <td>nlp, science, machine, software, datum, engine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demo Resume2.pdf</td>\n",
       "      <td>0.940091</td>\n",
       "      <td>nlp, science, machine, software, datum, engine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>res.pdf</td>\n",
       "      <td>0.921607</td>\n",
       "      <td>nlp, science, ideal, machine, datum, engineer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res2.pdf</td>\n",
       "      <td>0.921607</td>\n",
       "      <td>nlp, science, ideal, machine, datum, engineer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>res3.pdf</td>\n",
       "      <td>0.921607</td>\n",
       "      <td>nlp, science, ideal, machine, datum, engineer,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Filename  Match_Score  \\\n",
       "0   Demo Resume.pdf     0.940091   \n",
       "1  Demo Resume2.pdf     0.940091   \n",
       "2           res.pdf     0.921607   \n",
       "3          res2.pdf     0.921607   \n",
       "4          res3.pdf     0.921607   \n",
       "\n",
       "                                  Key_Skills_Matched  \n",
       "0  nlp, science, machine, software, datum, engine...  \n",
       "1  nlp, science, machine, software, datum, engine...  \n",
       "2  nlp, science, ideal, machine, datum, engineer,...  \n",
       "3  nlp, science, ideal, machine, datum, engineer,...  \n",
       "4  nlp, science, ideal, machine, datum, engineer,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_matching_keywords(resume_text, job_desc_text):\n",
    "    resume_words = set(resume_text.split())\n",
    "    job_words = set(job_desc_text.split())\n",
    "    \n",
    "    # find the intersection of both sets\n",
    "    common_words = resume_words.intersection(job_words)\n",
    "    return \", \".join(list(common_words))\n",
    "\n",
    "df['Key_Skills_Matched'] = df['Cleaned_Text'].apply(lambda x: get_matching_keywords(x, cleaned_job_desc))\n",
    "\n",
    "df[['Filename', 'Match_Score', 'Key_Skills_Matched']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c0494-37f7-4b1a-8aa4-5c8f228d2e8a",
   "metadata": {},
   "source": [
    "PHASE 3: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c5f13-bda5-4baa-9630-ec6536b20684",
   "metadata": {},
   "source": [
    "While this system provides an efficient way to rank candidates, it is subject to 'Algorithmic Bias.' In future iterations, I would implement Name Redaction and Weighting Adjustments to ensure the model focuses on skills rather than demographic indicators. Specifically, I would audit the model using 'Flip Tests' to ensure scores remain consistent regardless of gender-identifying language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef07d444-05fd-4fb3-a067-8633637989c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REDACTED NAME] is a great developer from New York.\n"
     ]
    }
   ],
   "source": [
    "def anonymize_text(text):\n",
    "    doc = nlp(text)\n",
    "    anonymized_text = text\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            # replace the name with [REDACTED]\n",
    "            anonymized_text = anonymized_text.replace(ent.text, \"[REDACTED NAME]\")\n",
    "            \n",
    "    return anonymized_text\n",
    "\n",
    "sample = \"John Doe is a great developer from New York.\"\n",
    "print(anonymize_text(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2b8c8-6a66-4c64-b933-1ef01ef03f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
